{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.load(\"preprocessed_texts.npy\", allow_pickle = True)\n",
    "labels = np.load(\"preprocessed_labels.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration for Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF | CountVectorization | BERT | DOC2VEC\n",
    "method = \"BERT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"CountVectorization\":\n",
    "    vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "    all_tokens = vectorizer.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"TF-IDF\":\n",
    "    vectorizer = TfidfVectorizer(min_df=0.0001, max_df=0.9, use_idf=False) #critical values selected from research papers \n",
    "    all_tokens = vectorizer.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>003</th>\n",
       "      <th>005</th>\n",
       "      <th>005380</th>\n",
       "      <th>006</th>\n",
       "      <th>00684</th>\n",
       "      <th>007</th>\n",
       "      <th>008</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>010</th>\n",
       "      <th>0100</th>\n",
       "      <th>011</th>\n",
       "      <th>014</th>\n",
       "      <th>015</th>\n",
       "      <th>016</th>\n",
       "      <th>019</th>\n",
       "      <th>02</th>\n",
       "      <th>020</th>\n",
       "      <th>...</th>\n",
       "      <th>zloti</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoellick</th>\n",
       "      <th>zoido</th>\n",
       "      <th>zoltan</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zon</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomph</th>\n",
       "      <th>zor</th>\n",
       "      <th>zoran</th>\n",
       "      <th>zour</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>zulia</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zweli</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  000th  001  002  003  005  005380  006  00684  007  008  \\\n",
       "0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "1  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "2  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "3  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "4  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "\n",
       "   00am  00pm   01  010  0100  011  014  015  016  019   02  020  ...  zloti  \\\n",
       "0   0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1   0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2   0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "3   0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4   0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "   zodiac  zoe  zoellick  zoido  zoltan  zombi  zon  zone  zones  zoo  zoom  \\\n",
       "0     0.0  0.0       0.0    0.0     0.0    0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "1     0.0  0.0       0.0    0.0     0.0    0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "2     0.0  0.0       0.0    0.0     0.0    0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "3     0.0  0.0       0.0    0.0     0.0    0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "4     0.0  0.0       0.0    0.0     0.0    0.0  0.0   0.0    0.0  0.0   0.0   \n",
       "\n",
       "   zoomph  zor  zoran  zour  zucker  zuckerberg  zuckerman  zulia  zulu  zuma  \\\n",
       "0     0.0  0.0    0.0   0.0     0.0         0.0        0.0    0.0   0.0   0.0   \n",
       "1     0.0  0.0    0.0   0.0     0.0         0.0        0.0    0.0   0.0   0.0   \n",
       "2     0.0  0.0    0.0   0.0     0.0         0.0        0.0    0.0   0.0   0.0   \n",
       "3     0.0  0.0    0.0   0.0     0.0         0.0        0.0    0.0   0.0   0.0   \n",
       "4     0.0  0.0    0.0   0.0     0.0         0.0        0.0    0.0   0.0   0.0   \n",
       "\n",
       "   zurich  zweli  zynga  \n",
       "0     0.0    0.0    0.0  \n",
       "1     0.0    0.0    0.0  \n",
       "2     0.0    0.0    0.0  \n",
       "3     0.0    0.0    0.0  \n",
       "4     0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 29521 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['00', '000', '0000', '000th', '001', '002', '003', '005', '005380',\n",
      "       '006',\n",
      "       ...\n",
      "       'zour', 'zucker', 'zuckerberg', 'zuckerman', 'zulia', 'zulu', 'zuma',\n",
      "       'zurich', 'zweli', 'zynga'],\n",
      "      dtype='object', length=29521)\n"
     ]
    }
   ],
   "source": [
    "# TODO Explanation\n",
    "\n",
    "features = pd.DataFrame(all_tokens.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "pd.set_option('display.max_columns', 50)\n",
    "display(features.head())\n",
    "print(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuters has been successfully removed\n"
     ]
    }
   ],
   "source": [
    "# Precautionary step: Check whether the custom stopwords\"R/reuters\" have been removed from the text\n",
    "for colname in features.columns:\n",
    "    if (colname == \"reuters\"):\n",
    "        print(\"Reuters has been successfully removed\")\n",
    "    if (colname == \"Reuters\"):\n",
    "        print(\"reuters has been successfully removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29521"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
      "['wish american happi new year leav . instead , give shout enemi , hater dishonest fake news media . former realiti show star one job . countri rapidli grow stronger smarter , want wish friend , support , enemi , hater , even dishonest fake news media , happi healthi new year , presid angri pant tweet . 2018 great year america ! countri rapidli grow stronger smarter , want wish friend , support , enemi , hater , even dishonest fake news media , happi healthi new year . 2018 great year america ! ( realdonaldtrump ) decemb 31 , 2017trump tweet went welll expect.what kind presid send new year greet like despic , petti , infantil gibberish ? ! lack decenc even allow rise gutter long enough wish american citizen happi new year ! bishop talbert swan ( talbertswan ) decemb 31 , 2017no one like calvin ( calvinstowel ) decemb 31 , 2017your impeach would make 2018 great year america , also accept regain control congress . miranda yaver ( mirandayav ) decemb 31 , 2017do hear talk ? includ mani peopl hate wonder ? hate ? alan sandov ( alansandoval13 ) decemb 31 , 2017who use word hater new year wish ? ? marlen ( marlene399 ) decemb 31 , 2017you say happi new year ? koren pollitt ( korencarpent ) decemb 31 , 2017here new year eve tweet 2016.happi new year , includ mani enemi fought lost badli know . love ! ( realdonaldtrump ) decemb 31 , 2016thi noth new . years.trump direct messag enemi hater new year , easter , thanksgiv , anniversari 9/11 . pic.twitter.com/4fpae2kypa daniel dale ( ddale8 ) decemb 31 , 2017trump holiday tweet clearli presidential.how long work hallmark becom presid ? steven goodin ( sgoodin ) decemb 31 , 2017he alway like . . . differ last year , filter break . roy schulz ( thbthttt ) decemb 31 , 2017who , apart teenag use term hater ? wendi ( wendywhistl ) decemb 31 , 2017he fuck 5 year old know ( rainyday80 ) decemb 31 , 2017so , peopl vote hole think would chang got power , wrong ! 70-year-old men chang year older.photo andrew burton/getti imag . '\n",
      " 'hous intellig committe chairman devin nune go bad day . assumpt , like mani us , christoph steele-dossi prompt russia investig lash depart justic fbi order protect . happen , dossier start investig , accord document obtain new york times.form campaign advis georg papadopoulo drunk wine bar reveal knowledg russian opposit research hillari clinton.on top , papadopoulo covfef boy , administr alleg . much larger role , none damn drunken fool wine bar . coffe boy help arrang new york meet presid abdel fattah el-sisi egypt two month elect . known former aid set meet world leader , team ran mere coffe boy.in may 2016 , papadopoulo reveal australian diplomat alexand downer russian offici shop around possibl dirt then-democrat presidenti nomine hillari clinton . exactli much mr. papadopoulo said night kensington wine room australian , alexand downer , unclear , report state . two month later , leak democrat email began appear onlin , australian offici pass inform mr. papadopoulo american counterpart , accord four current former american foreign offici direct knowledg australian role . papadopoulo plead guilti lie f.b.i . cooper wit special counsel robert mueller team.thi presid . badli script realiti tv show.photo win mcnamee/getti imag . '\n",
      " 'friday , reveal former milwauke sheriff david clark , consid homeland secur secretari administr , email scandal own.in januari , brief run-in plane clark fellow passeng dan black , later detain polic reason whatsoev , except mayb feel hurt . clark messag polic stop black deplan , , search warrant execut fbi see exchanges.clark call fake news even though copi search warrant internet . unintimid lib media attempt smear discredit fake news report design silenc , former sheriff tweet . continu poke eye sharp stick bitch slap scum bag til get . attack better peopl # maga unintimid lib media attempt smear discredit fake news report design silenc . continu poke eye sharp stick bitch slap scum bag til get . attack better peopl # maga pic.twitter.com/xtzw5pdu2b david a. clark , jr. ( sheriffclark ) decemb 30 , 2017he stop there.break news ! lie lib media make fake news smear , antidot go right . punch nose & make tast blood . noth get bulli like lie lib media attent better give tast blood # neverbackdown pic.twitter.com/t2ny2pshcr david a. clark , jr. ( sheriffclark ) decemb 30 , 2017the internet call out.thi local newspap search warrant fake , chose file charg time mean ! especi continu lie . month decis charg clark , email search warrant file http : //t.co/zcbyc4wp5b keithleblanc ( keithleblanc63 ) decemb 30 , 2017i hope rest villag peopl implic . kirk ketchum ( kirkketchum ) decemb 30 , 2017slaw , bake potato , french fri ? pic.twitter.com/fwfxszupxi alt- immigr ( alt_usci ) decemb 30 , 2017pic.twitter.com/ymsobljfxu pendulum swinger ( pendulumswngr ) decemb 30 , 2017you call polic friend stand someon made fun hat chri jackson ( chriscjackson ) decemb 30 , 2017i , master pshop hat , seem never tire . think steeli resolv one visibl eye pic.twitter.com/dwr5k8zezv chri mohney ( chrismohney ) decemb 30 , 2017are indic finger mani peopl die jail ? think finger short , dipshit ike barinholtz ( ikebarinholtz ) decemb 30 , 2017rofl . internet tough guy fake flair . pic.twitter.com/ulcfddhkdi kellmecrazi ( kel_moonfac ) decemb 30 , 2017you edgi , buddi . mrs. smh ( mrssmh2 ) decemb 30 , 2017i break applebe ? aaron ( feltrrr2 ) decemb 30 , 2017are tri earn still relev badg ? circusrebel ( circusdrew ) decemb 30 , 2017make sure hydrat , drink lot water . rumor prison deni water prison offici . robert klinc ( robertklinc1 ) decemb 30 , 2017terril thoma , 38-year-old black man die thirst clark milwauke counti jail cell april , victim homicid . thought point . repeat enough.photo spencer platt/getti imag . '\n",
      " ...\n",
      " 'minsk ( ) - shadow disus soviet-era factori minsk , street line eclect bar , art galleri yoga studio becom vigil eye belarussian author . place like island , said yegor , 21 , work popular bar hooligan . street freedom . govern presid alexand lukashenko , rule belaru past 23 year boast last dictat europ , littl toler opposit . power polic forc fear state secur keep citizen check . polic patrol rare oktyabrskaya , partli due locat out-of-the-way peninsula bend river svislach . first restaur open 2012 , visitor came rank among fashion quarter minsk . grow popular oktyabrskaya investor belgazprombank , subsidiari state-own russian lender gazprombank , big plan district . earlier year bank purchas part factori intend turn galleri , restaur theater complex . manufactur sector entir abandon oktyabrskaya - one machine-mak factori name 1917 octob revolut ( mzor ) still oper . financi difficulti prompt state-own mzor leas sell facil oktyabrskaya develop , firm still maintain product reduc workforc . mikhail , work factori 42 year , said approv influx new hipster busi . street come back life , said . oktyabrskaya long-term futur ultim depend author good favor , cultur analyst maksim zhbankov said . toler . say someon turn tomorrow say decid tear , said . '\n",
      " 'moscow ( ) - vatican secretari state cardin pietro parolin said tuesday posit momentum behind idea pope franci visit russia , suggest work done happen . parolin , speak joint news confer moscow alongsid russian foreign minist sergei lavrov , give date possibl visit . eastern western branch christian split apart 1054. pope , leader world 1.2 billion cathol , seek improv tie , last year cuba held first ever meet roman cathol pope russian orthodox patriarch . parolin said also use talk russian capit also rais certain difficulti face cathol church russia . said moscow vatican disagre plight christian certain part world . elabor . parolin , due later tuesday meet patriarch kiril , head russian orthodox church , said also believ russia could play import role came help solv crisi venezuela close relat caraca . '\n",
      " 'jakarta ( ) - indonesia buy 11 sukhoi fighter jet worth $ 1.14 billion russia exchang cash indonesian commod , two cabinet minist said tuesday . southeast asian countri pledg ship $ 570 million worth commod addit cash pay suhkoi su-35 fighter jet , expect deliv stage start two year . indonesian trade minist enggartiasto lukita said joint statement defenc minist ryamizard ryacudu detail type volum commod still negoti . previous said export could includ palm oil , tea , coffe . deal expect finalis soon indonesian state trade compani pt perusahaan perdangangan indonesia russian state conglomer rostec . russia current face new round u.s.-impos trade sanction . meanwhil , southeast asia largest economi tri promot palm oil product amid threat cut consumpt european union countri . indonesia also tri modern age air forc string militari aviat accid . indonesia , $ 411 million trade surplu russia 2016 , want expand bilater cooper tourism , educ , energi , technolog aviat among other . ']\n",
      "Keys       : ['input_type_ids', 'input_word_ids', 'input_mask']\n",
      "Shape      : (44898, 128)\n",
      "Word Ids   : [[  101  4299  2137 ...  2095  2637   102]\n",
      " [  101  7570  2271 ...  2884  6638   102]\n",
      " [  101  5958  1010 ... 26202  3239   102]\n",
      " ...\n",
      " [  101 20790  1006 ... 17917  2483   102]\n",
      " [  101  4924  1006 ...  3736 17603   102]\n",
      " [  101 14426  1006 ...  3066  5987   102]]\n",
      "Input Mask : [[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "Type Ids   : [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "if method == \"BERT\":\n",
    "    tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\"\n",
    "    tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "\n",
    "    print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "    print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n",
    "\n",
    "    \n",
    "    bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "    #if \"OSError: SavedModel file does not exist\" occurs, navigate to the indicated folder and delete it\n",
    "    \n",
    "    text_test = texts\n",
    "    text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "    #print(text_test)\n",
    "    print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "    print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "    print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"]}')\n",
    "    print(f'Input Mask : {text_preprocessed[\"input_mask\"]}')\n",
    "    print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOC2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"DOC2VEC\":\n",
    "    # TODO\n",
    "    print(\"sdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"TF-IDF\":\n",
    "    scipy.sparse.save_npz(\"training_input\", all_tokens)\n",
    "    np.save(\"training_labels\", labels)\n",
    "\n",
    "if method == \"BERT\":\n",
    "    a_file = open(\"bert_preprocessed.pkl\", \"wb\")\n",
    "    pickle.dump(text_preprocessed, a_file)\n",
    "    a_file.close()\n",
    "    np.save(\"training_labels\", labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3482ef3323ad09bbcf0e8d550b08b88f7234f6ea94425e7e69b98a6bf876e57c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
